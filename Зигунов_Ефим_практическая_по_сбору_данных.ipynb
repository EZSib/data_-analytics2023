{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6rKWxkGBhRvH",
        "cJL8g8Cy96Rd",
        "xGVZmQlN9k8N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Большая просьба сдавать работы на проверку, в которых сразу выполнены четыре обязательных задания. "
      ],
      "metadata": {
        "id": "oftpQvqjdgbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 1. Библиотека VK API"
      ],
      "metadata": {
        "id": "XslJSFkAe5-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите код, который получает список названия школ города Кемерово с помощью библиотеки vk_api и записывает результаты в файл JSON."
      ],
      "metadata": {
        "id": "Fv1R9qMftlt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Решение без апи_вк"
      ],
      "metadata": {
        "id": "AiSumKEqGcZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json,re\n",
        "from collections import defaultdict\n",
        "\n",
        "ACCESS_TOKEN = '' \n",
        "METHOD_NAME = 'database.getSchools'\n",
        "URL = f'https://api.vk.com/method/{METHOD_NAME}'\n",
        "pattern = r'[/.а-яА-ЯёЁ№()0-9\\- ]+'\n",
        "\n",
        "params = {\n",
        "    \"access_token\": ACCESS_TOKEN,\n",
        "    \"city_id\": 64,\n",
        "    \"sort\": 6,\n",
        "    \"v\": 5.131\n",
        "}\n",
        "final_res = defaultdict(list)\n",
        "res = requests.get(URL, params=params).text\n",
        "res1 = re.findall(pattern, res)                    # отбор регуляркой\n",
        "res1 = [i for i in res1 if  any(map(lambda x: x in [(lambda c: chr(c))(i) for i in range(1072, 1104)], i))]\n",
        "res = res.split(':')       # отбор не регуляркой \n",
        "res = [i.replace('},{\"id\"','').replace('}]}}','') for i in res if  any(map(lambda x: x in [(lambda c: chr(c))(i) for i in range(1072, 1104)],i )) ]\n",
        "for j in res1:\n",
        "    final_res[j[:j.find('№')]].append(j[j.rfind('№'):])\n",
        "print(*final_res.items(), sep='\\n')\n",
        "with open('kemerovo_schools.json', 'w', encoding='utf8') as file:\n",
        "    json.dump(final_res, file, ensure_ascii=False, indent=2)\n",
        "#таким образом уменьшаем коллизию бд сразу при создании файла в разы\n",
        "# при необходимости можно полирнуть отбор, чтоб корректно отображал именные\n",
        "# учебные заведения(в отдельные словари) и без номеров\n"
      ],
      "metadata": {
        "id": "rufJxiJufcPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d992395-60ec-47d8-fc88-8b198e248ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Школа ', ['№ 1', '№ 2', '№ 3', '№ 4', '№ 5', '№ 7', '№ 8', '№ 10', '№ 11', '№ 12 им. В. Д. Волошиной', '№ 14', '№ 15', '№ 16 им. Р. Г. Цецульникова', '№ 17', '№ 18 им. Н. И. Жадовца', '№ 19', '№ 20', '№ 21', '№ 23', '№ 24', '№ 25', '№ 26', '№ 28', '№ 31 им. В. Д. Мартемьянова', '№ 32 им. А. А. Капитонова', '№ 33 им. А. В. Бобкова', '№ 34 им. С. А. Амелина', '№ 35 им. Л. И. Соловьева', '№ 36', '№ 37 им. Г. Г. Новикова', '№ 38', '№ 39', '№ 40 им. Катасонова С.А.', '№ 41', '№ 42', '№ 43', '№ 44 им. М. Я. Вознесенского', '№ 45', '№ 46', '№ 47', '№ 48 им. М. Ю. Коломина', '№ 49', '№ 50 им. Бабенко А. А.', '№ 51', '№ 52', '№ 54', '№ 55', '№ 56', '№ 58', '№ 59', '№ 60', '№ 61', '№ 62', '№ 65', '№ 66'])\n",
            "('Гимназия ', ['№ 1', '№ 17', '№ 21', '№ 23', '№ 25', '№ 41', '№ 42'])\n",
            "('Детская музыкальная школа ', ['№ 1', '№ 2', '№ 4', '№ 43'])\n",
            "('Спортивная школа олимпийского резерва ', ['№ 1'])\n",
            "('Детская художественная школа ', ['№ 1', '№ 19'])\n",
            "('Профессиональный лицей ', ['№ 1'])\n",
            "('Профессионально-техническое училище ', ['№ 1'])\n",
            "('Детско-юношеская спортивная школа ', ['№ 2', '№ 3', '№ 4'])\n",
            "('Профессиональное училище ', ['№ 3', '№ 44', '№ 48', '№ 65'])\n",
            "('Детская школа искусств ', ['№ 5', '№ 14', '№ 15', '№ 19', '№ 45', '№ 46', '№ 50'])\n",
            "('Школа-интернат ', ['№ 6', '№ 22', '№ 27', '№ 30', '№ 53', '№ 64'])\n",
            "('Спортивная школа ', ['№ 6'])\n",
            "('Вечерняя (сменная) школа ', ['№ 12'])\n",
            "('Лицей ', ['№ 23', '№ 62'])\n",
            "('Детский сад ', ['№ 25', '№ 49'])\n",
            "('Кемеровский техникум индустрии питания и сферы услуг (бывш. ПЛ 49', [')'])\n",
            "('Начальная школа ', ['№ 63', '№ 67'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vk_api"
      ],
      "metadata": {
        "id": "axtt0peTMxJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vk_api, json,re\n",
        "from collections import defaultdict\n",
        "\n",
        "ACCESS_TOKEN = '' \n",
        "pattern = r'[/.а-яА-ЯёЁ№()0-9\\- ]+'\n",
        "try:\n",
        "  vk_session = vk_api.VkApi(token=ACCESS_TOKEN)\n",
        "  vk = vk_session.get_api()\n",
        "  city = vk.database.getCities(country_id=1, q='Кемерово', count=1)\n",
        "  city_id = city['items'][0]['id'] if city['count'] > 0 else None\n",
        "  res_dict = vk.database.getSchools(country_id=1, city_id=city_id)\n",
        "  res = str(res_dict)\n",
        "\n",
        "  final_res = defaultdict(list)\n",
        "#   res1 = re.findall(pattern, res)                    # отбор регуляркой\n",
        "#   res1 = [i for i in res1 if  any(map(lambda x: x in [(lambda c: chr(c))(i) for i in range(1072, 1104)], i))]\n",
        "\n",
        "#   res = res.split(':')       # отбор не регуляркой \n",
        "#   res = [i.replace('},{\"id\"','').replace('}]}}','') for i in res if  \n",
        "#         any(map(lambda x: x in [(lambda c: chr(c))(i) for i in range(1072, 1104)],i )) ]\n",
        "\n",
        "#   for j in res1:\n",
        "#       final_res[j[:j.find('№')]].append(j[j.rfind('№'):])\n",
        "#   print(*final_res.items(), sep='\\n')\n",
        "# except Exception as ex:\n",
        "#   print(f'ERROR: {ex}')\n",
        "\n",
        "# with open('kemerovo_schools.json', 'w', encoding='utf8') as file:\n",
        "#     json.dump(final_res, file, ensure_ascii=False, indent=1)\n",
        "  for j in [i['title'].split() for i in res_dict['items']]:\n",
        "    if len(j) == 3:\n",
        "      final_res[j[0]].append(f'{j[1]} {j[2]}')\n",
        "    if len(j) == 4:\n",
        "      final_res[f'{j[0]} {j[1]}'].append(f'{j[2]} {j[3]}')\n",
        "    if len(j) == 5:\n",
        "      final_res[f'{j[0]} {j[1]} {j[2]}'].append(f'{j[3]} {j[4]}')\n",
        "    if len(j) == 6:\n",
        "      final_res[f'{j[0]} {j[1]} {j[2]} {j[3]}'].append(f'{j[4]} {j[5]}')\n",
        "    if len(j) >6:\n",
        "      final_res[' '.join([k for k in j if k=='.' or k.isalpha()])].append(' '.join([k for k in j if k != '.' or not k.isalpha()]))\n",
        "except Exception as ex:\n",
        "  print(f'ERROR: {ex}')\n",
        "with open('kemerovo_schools_vk.json', 'w', encoding='utf8') as file:\n",
        "     json.dump(final_res, file, ensure_ascii=False, indent=1)"
      ],
      "metadata": {
        "id": "1BVvxQo-Ncij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "v4_ZEnTShH_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Получаем токен доступа к API Вконтакте\n",
        "2.   Инициализируем сессию библиотеки VK_API с помощью токена доступа\n",
        "3. Получаем доступ с помощью VK_API к API «ВКонтакте» методом get_api\n",
        "4. Следуя методу из документации для получения городов и используя библиотеку VK_API, составляем запрос на получение информации о городе «Кемерово» и получаем его id из ответа на запрос\n",
        "5. Следуя методу из документации для получения школ и используя библиотеку VK_API, составляем запрос на получение информации о школах города «Кемерово» (по найденному id) и получаем список названия школ\n",
        "10. Конкретный формат не указан, поэтому создаем JSON с удобными ключами.<br>Например: result: {schools: [...]}\n",
        "11. Записываем созданный  словарик  в файл с форматом JSON \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYJIXxVOBmHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 2. Запись данных в CSV формат"
      ],
      "metadata": {
        "id": "N1UzGf1CtVfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью методов API «ВКонтакте» получите 1000 подписчиков группы «Лентач», отсортирванных по дате регистрации.\n",
        "\n",
        "Вам необходимо собрать следующие данные в CSV файл: пол, название город, семейное положение (ФИО партнера не указывать)."
      ],
      "metadata": {
        "id": "Rg-gNSTzfA7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Решение без апи_вк"
      ],
      "metadata": {
        "id": "kCkiwquhGuSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, csv\n",
        "\n",
        "ACCESS_TOKEN = ''\n",
        "METHOD_NAME = 'groups.getMembers'\n",
        "URL = f'https://api.vk.com/method/{METHOD_NAME}'\n",
        "\n",
        "\n",
        "params = {\n",
        "    \"access_token\": ACCESS_TOKEN,\n",
        "    'group_id' : 29534144,\n",
        "    'fields' : 'sex, city, relation',\n",
        "    'sort': 'id_asc',\n",
        "    \"v\": 5.131\n",
        "}\n",
        "relations = {\n",
        "  1 : \"не женат/не замужем\",\n",
        "  2 : \"есть друг/есть подруга\",\n",
        "  3 : \"помолвлен/помолвлена\",\n",
        "  4 : \"женат/замужем\",\n",
        "  5 : \"всё сложно\",\n",
        "  6 : \"в активном поиске\",\n",
        "  7 : \"влюблён/влюблена\",\n",
        "  8 : \"в гражданском браке\",\n",
        "  0 : \"не указано\"\n",
        "}\n",
        "seex = {0: 'не указан', 1: 'Ж', 2: 'М'}\n",
        "res = requests.get(URL, params=params).json()\n",
        "res = res['response'][\"items\"]\n",
        "res_list = []\n",
        "for r in res:\n",
        "    if 'city' in r:\n",
        "        city = r['city']['title']\n",
        "    else: city = 'Город-Герой'\n",
        "    # sex = r.get('sex', 0)\n",
        "    # relation = r.get('relation', 0)\n",
        "    res_list.append({'city' : city,'sex' : seex[r.get('sex', 0)], 'ralation' : relations[r.get('relation', 0)]})\n",
        "\n",
        "\n",
        "with open('lentach.csv', 'w', encoding='utf8', newline='') as file:\n",
        "        writer = csv.DictWriter(file,fieldnames=res_list[0])\n",
        "        writer.writeheader()\n",
        "        for row in res_list:\n",
        "            writer.writerow(row)\n",
        "# import pandas as pd\n",
        "# f = pd.read_csv(\"lentach.csv\")\n",
        "# keep_col = ['relation','sex','city']\n",
        "# new_f = f[keep_col]\n",
        "# new_f.to_csv(\"lentach_pd.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "eSslPXrGfDRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vk_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDqAjG17G8cJ",
        "outputId": "7ddc0b56-8584-42de-d045-6d3f31dbed3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vk_api\n",
            "  Downloading vk_api-11.9.9-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from vk_api) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->vk_api) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->vk_api) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->vk_api) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->vk_api) (3.4)\n",
            "Installing collected packages: vk_api\n",
            "Successfully installed vk_api-11.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vk_api, csv\n",
        "\n",
        "ACCESS_TOKEN = ''\n",
        "\n",
        "try:\n",
        "  vk_session = vk_api.VkApi(token=ACCESS_TOKEN)\n",
        "  vk = vk_session.get_api()\n",
        "  group = vk.groups.search(q='Лентач', count=1)\n",
        "  group_id = group['items'][0]['id'] if group['count'] > 0 else None\n",
        "    \n",
        "  res = vk.groups.getMembers(group_id=group_id, \n",
        "                             sort='id_asc', count=1000, \n",
        "                             fields='sex, city, relation')[\"items\"]\n",
        "  \n",
        "\n",
        "  relations = {\n",
        "    1 : \"не женат/не замужем\",\n",
        "    2 : \"есть друг/есть подруга\",\n",
        "    3 : \"помолвлен/помолвлена\",\n",
        "    4 : \"женат/замужем\",\n",
        "    5 : \"всё сложно\",\n",
        "    6 : \"в активном поиске\",\n",
        "    7 : \"влюблён/влюблена\",\n",
        "    8 : \"в гражданском браке\",\n",
        "    0 : \"не указано\"\n",
        "  }\n",
        "  seex = {0: 'не указан', 1: 'Ж', 2: 'М'}\n",
        "  res_list = []\n",
        "  for r in res:\n",
        "      if 'city' in r:\n",
        "          city = r['city']['title']\n",
        "      else: city = 'Город-Герой'\n",
        "      # sex = r.get('sex', 0)\n",
        "      # relation = r.get('relation', 0)\n",
        "      res_list.append({'city' : city,'sex' : seex[r.get('sex', 0)], 'ralation' : relations[r.get('relation', 0)]})\n",
        "except Exception as ex:\n",
        "  print(f'ERROR: {ex}') \n",
        "\n",
        "with open('lentach.csv', 'w', encoding='utf8', newline='') as file:\n",
        "        writer = csv.DictWriter(file,fieldnames=res_list[0])\n",
        "        writer.writeheader()\n",
        "        for row in res_list:\n",
        "            writer.writerow(row)"
      ],
      "metadata": {
        "id": "H6WvgElmHJJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "6rKWxkGBhRvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Получаем токен доступа к API Вконтакте\n",
        "2. Инициализируем сессию библиотеки VK_API с помощью токена доступа\n",
        "3. Получаем доступ с помощью VK_API к API вконтакте методом get_api\n",
        "4. Следуя методу из документации для получения сообществ и используя библиотеку VK_API, составляем запрос на получение информации о сообществе «Лентач» и получаем его id из ответа на запрос\n",
        "5. Следуя методу (getMembers) из документации для получения участников сообщества и используя библиотеку VK_API, составляем запрос на получение информации о участниках сообщества «Лентач» (по найденному id) и получаем пол, город и СП каждого из участников\n",
        "6. С помощью CSV библиотеки записываем полученные данные в файл с форматом csv\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNVe0qbDCbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 3. Скрещиваем Selenium и BeautifulSoup"
      ],
      "metadata": {
        "id": "XFUPJo-qsusT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберите информацию с сайта nbcomputers.ru (https://www.nbcomputers.ru/catalog/noutbuki/) о ноутбуках данного интернет-магазина.\n",
        "<br>\n",
        "Данные, которые необходимы:\n",
        "* Название ноутбука\n",
        "* Цена ноутбука\n",
        "* Код товара\n",
        "\n",
        "Результат необходимо записать в CSV файл.\n",
        "<br>\n",
        "*(совет: обязательно делайте различные временные промежутки между прокликами)*"
      ],
      "metadata": {
        "id": "9O8NOJs51u8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустить в colab не получилось, использую вин7 а он не поддерживает веб-драйвер необходимой версии. В pycharme собирает csv как надо, при необходимости приложу файл\\проект."
      ],
      "metadata": {
        "id": "bhIxAw1hCvgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "\n",
        "service = Service(executable_path='/usr/lib/chromium-browser/chromedriver')\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "URL = f'https://www.nbcomputers.ru/catalog/noutbuki/?page=1'\n",
        "\n",
        "res_name_price_id = []\n",
        "\n",
        "driver.implicitly_wait(5)\n",
        "\n",
        "# определяем функцию для парсинга в бс4\n",
        "def parse(URL_page):\n",
        "    driver.get(URL)\n",
        "    html = driver.page_source\n",
        "\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    all_cards = soup.select('article')\n",
        "    for card in all_cards:\n",
        "        name = (card.select_one('.iVdSZe').text).split('&')[0]\n",
        "        price = ''.join(list((i for i in (card.select_one('.sc-96470d6e-2').text) if i.isdigit())))\n",
        "        id = card.select_one('.cfXmWO').text.split()[1].strip()\n",
        "        res_name_price_id.append({'name': name, 'price': price, 'id': id})\n",
        "\n",
        "\n",
        "try:\n",
        "    parse(URL)\n",
        "except Exception as ex:\n",
        "    print(f'Error: {ex}')\n",
        "parent_element = driver.find_element(By.XPATH, '//*[@id=\"catalog-listing\"]/div[2]/ul/li[8]/a')\n",
        "\n",
        "\"\"\"Тут начинается самое смешное: по теническим причинам, для меня была отрезана возможность запарсить страницу\n",
        "используя кнопку \"показать еще\", и для того, чтобы использовать селениум хоть как то, я заставил \n",
        "нажимать его каждую последующую страницу, нашел 2 способа - XPath и сабстрока,  по сабстроке\n",
        "он открывал новую вкладку в браузере при переходе, а у меня по какой то причине не переключаются\n",
        "при помощи window_handles-switch_to.window, поэтому принял решение искать кнопки по XPath. \n",
        "Для этого разработал алгоритм который присутсвует ниже: end находит номер последней страницы,\n",
        "словарь открывает первые 5 страниц и последнюю (на сайте при подгрузки, кнопки смещаются),\n",
        "и условие которое прописывает пусть на все остальные страницы\"\"\"\n",
        "end = int(driver.execute_script('return arguments[0].firstChild.textContent;', parent_element).strip())\n",
        "\n",
        "\"\"\"А потом я нашел кнопку \"следущая страница..:=)\"\"\"\n",
        "dict_XPath = {2: 3, 3: 4, 4: 5, 5: 6}\n",
        "dict_XPath[end] = 8\n",
        "try:\n",
        "    for i in range(2, end+1):\n",
        "        if 5 < i < end:\n",
        "            j = 7\n",
        "        else:\n",
        "            j = dict_XPath[i]\n",
        "        driver.implicitly_wait(5)\n",
        "        actions = ActionChains(driver)\n",
        "        wait = WebDriverWait(driver, timeout=15)\n",
        "\n",
        "        actions.move_to_element(driver.find_element(By.XPATH, f'//*[@id=\"catalog-listing\"]/div[2]/ul/li[{j}]/a'))\n",
        "        actions.perform()\n",
        "        actions.scroll_to_element(driver.find_element(By.XPATH, f'//*[@id=\"catalog-listing\"]/div[2]/ul/li[{j}]/a'))\n",
        "        actions.perform()\n",
        "        # link_page = driver.find_element(By.CSS_SELECTOR, f'ul > li.ant-pagination-item.ant-pagination-item-{i} > a').get_attribute('href') #  пытался очень долго, стабильную ссылку получить не выходит\n",
        "        wait.until(EC.element_to_be_clickable((By.XPATH, f'//*[@id=\"catalog-listing\"]/div[2]/ul/li[{j}]/a'))).click()\n",
        "\n",
        "        URL = f'{URL[:URL.index(\"=\")+1]}{i}'\n",
        "        parse(URL)\n",
        "except Exception as ex:\n",
        "    print(f'Error: {ex}')\n",
        "print(len(res_name_price_id))\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "with open('bs4_selen.css', 'w', encoding='utf8', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=res_name_price_id[0])\n",
        "    writer.writeheader()\n",
        "    for row in res_name_price_id:\n",
        "        writer.writerow(row)\n",
        "    "
      ],
      "metadata": {
        "id": "ORwgF2mYffFf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "5391f52f-a88b-4acd-8458-374d3941bdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ed878e9950d5>:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(executable_path='/usr/lib/chromium-browser/chromedriver', options=chrome_options)\n",
            "WARNING:selenium.webdriver.common.selenium_manager:Incompatible release of chromedriver (version 90.0.4430.212) detected in PATH: /usr/bin/chromedriver\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SessionNotCreatedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ed878e9950d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--headless\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--no-sandbox\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/usr/lib/chromium-browser/chromedriver'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://www.nbcomputers.ru/catalog/noutbuki/?page=1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_log_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m                 command_executor=ChromiumRemoteConnection(\n\u001b[1;32m    106\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mw3c_caps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_w3c_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw3c_caps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"sessionId\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 111\nCurrent browser version is 90.0.4430.212 with binary path /usr/bin/chromium\nStacktrace:\n#0 0x55a510c92243 <unknown>\n#1 0x55a510a567a6 <unknown>\n#2 0x55a510a83e5c <unknown>\n#3 0x55a510a7ebf3 <unknown>\n#4 0x55a510a7b49b <unknown>\n#5 0x55a510abd2a7 <unknown>\n#6 0x55a510abc8cf <unknown>\n#7 0x55a510ab3e53 <unknown>\n#8 0x55a510a869ea <unknown>\n#9 0x55a510a87b2e <unknown>\n#10 0x55a510ce6d5e <unknown>\n#11 0x55a510ceaa80 <unknown>\n#12 0x55a510ccc8b0 <unknown>\n#13 0x55a510cebb63 <unknown>\n#14 0x55a510cbdf75 <unknown>\n#15 0x55a510d0e998 <unknown>\n#16 0x55a510d0eb27 <unknown>\n#17 0x55a510d29c23 <unknown>\n#18 0x7fbedd733609 start_thread\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи в Colab (простой):"
      ],
      "metadata": {
        "id": "wLgQzytJh7V_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможный алгоритм решения задачи в коллабе (простой):\n",
        "1. Установливаем параметры для headless браузера\n",
        "2. Инициализацируем сессию браузера\n",
        "3. Переходим по данной ссылке\n",
        "4. Устанавливаем неявное ожидание\n",
        "5. Инициализируем явное ожидание для нажатия на кнопку \"Больше\"\n",
        "6. С помощью бесконечного цикла жмем на кнопку методом click, пока она кликабельна  (ну и не забываем про селектор)\n",
        "4. Оборачиваем все в trt except.Когда вылетит с ошибкой того, что кнопка не кликабельна => прогрузили все карточки\n",
        "\n",
        "5. С помощью BS находим блок карточек\n",
        "6. Поочереднно собираем необходимые данные с карточки\n",
        "7. Записываем все в файл с форматом csv, используя CSV библиотеку\n",
        "\n"
      ],
      "metadata": {
        "id": "TfOWoc4glonj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 4. Фреймворк Scrapy"
      ],
      "metadata": {
        "id": "2kKiYGTFfSpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберите информацию о заквасках с сайта pro-syr.ru (https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
        "\n",
        "Необходимо собрать следующие данные:\n",
        "* Название продукта\n",
        "* Цена\n",
        "* Есть ли продукт в наличии\n",
        "\n",
        "Результат должен быть записан в CSV файл"
      ],
      "metadata": {
        "id": "A6UOPxtk563f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scrapy\n"
      ],
      "metadata": {
        "id": "tP7krMMSQ4hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy startproject last_sir\n",
        "\n"
      ],
      "metadata": {
        "id": "65zmezdBSMfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sir/sirsir/last_sir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFTdX376TM9m",
        "outputId": "16a27202-6f44-4919-c3ca-5268593d28fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sir/sirsir/last_sir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class SirSpider(scrapy.Spider):\n",
        "    name = \"last_sir\"\n",
        "    start_urls = [\"https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/\"]\n",
        "\n",
        "    def parse(self, response):\n",
        "        links = response.css(\"div.row.grid-july div.nameproduct a::attr(href)\")\n",
        "        for link in links:\n",
        "            yield response.follow(link, self.parse_product)\n",
        "\n",
        "        link = response.css(\"div.col-sm-12 ul.pagination a::attr(href)\")[-1].get()\n",
        "        yield response.follow(link, self.parse)\n",
        "\n",
        "    def parse_product(self, response):\n",
        "        yield {\n",
        "            \"name\": response.css(\"div.col-md-9 h1::text\").get(),\n",
        "            \"price\": response.css(\"li.price span::text\").get(),\n",
        "            \"in_stock\": response.css(\"div.product-description b::text\").get()\n",
        "        }"
      ],
      "metadata": {
        "id": "EO-otAz7JuMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zUq-Xwlfgjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sir/sirsir/last_sir\n",
        "\n",
        "!scrapy crawl last_sir -o vsysnii_sir.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxd1yuolSrdP",
        "outputId": "d1b0e64e-0b27-4e76-fa5b-d7dc388f90f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sir/sirsir/last_sir\n",
            "2023-03-29 16:51:32 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: last_sir)\n",
            "2023-03-29 16:51:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.9.16 (main, Dec  7 2022, 01:11:51) - [GCC 9.4.0], pyOpenSSL 23.1.1 (OpenSSL 3.0.8 7 Feb 2023), cryptography 39.0.2, Platform Linux-5.10.147+-x86_64-with-glibc2.31\n",
            "2023-03-29 16:51:32 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'last_sir',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'last_sir.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['last_sir.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2023-03-29 16:51:32 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2023-03-29 16:51:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2023-03-29 16:51:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2023-03-29 16:51:32 [scrapy.extensions.telnet] INFO: Telnet Password: c94d52365664b117\n",
            "2023-03-29 16:51:32 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2023-03-29 16:51:32 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2023-03-29 16:51:32 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2023-03-29 16:51:32 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2023-03-29 16:51:32 [scrapy.core.engine] INFO: Spider opened\n",
            "2023-03-29 16:51:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2023-03-29 16:51:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2023-03-29 16:51:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/robots.txt> (referer: None)\n",
            "2023-03-29 16:51:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/> (referer: None)\n",
            "2023-03-29 16:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/bioantibut/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/bioantibut/>\n",
            "{'name': 'Мезофильная закваска для сыра Биоантибут', 'price': '108 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-choosit-probat-222/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zashitnaya/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-choosit-probat-222/>\n",
            "{'name': 'Закваска Danisco Choosit Probat 222 LYO (50 DCU)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/uglich-7-k-1-ea/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zashitnaya/>\n",
            "{'name': 'Закваска «Защитная» Lactoferm ECO - на 250 литров молока', 'price': '695 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-rm32/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/uglich-7-k-1-ea/>\n",
            "{'name': 'Ускоритель созревания сыра БК-Углич-№7К (1ЕА)', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-rm32/>\n",
            "{'name': 'Закваска Danisco CHOOZIT RM 32/34 LYO (50 DCU)', 'price': '1 070 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/fermerskiy-syr/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-rm-32-34-325-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uskoritel-sozrevaniya-syra-uglich-7k/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-choozit-bt-01/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/fermerskiy-syr/>\n",
            "{'name': 'Закваска «Фермерский сыр» Lactoferm ECO - на 250 литров молока', 'price': '695 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-rm-32-34-325-dcu/>\n",
            "{'name': 'Закваска Danisco CHOOZIT RM 32/34 LYO (325 DCU)', 'price': '3 350 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uskoritel-sozrevaniya-syra-uglich-7k/>\n",
            "{'name': 'Ускоритель созревания сыра БК-Углич-№7К (0,1ЕА)', 'price': '108 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-choozit-bt-01/>\n",
            "{'name': 'Мезофильная закваска Danisco Choozit  BT 01/02 LYO (50 DCU)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-md-88-89-99-50-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-md-88-89-99-50-dcu/>\n",
            "{'name': 'Ароматообразующая закваска Danisco MD88/89/99 (50 DCU)', 'price': '1 075 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/myagkiy-syr-lactaferm/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-bioantibut-tp/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/myagkiy-syr-lactaferm/>\n",
            "{'name': 'Закваска «Мягкий сыр» Lactoferm ECO - на 250 литров молока', 'price': '695 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-bioantibut-tp/>\n",
            "{'name': 'Мезо-термофильная закваска Биоантибут-ТП', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-6/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-hansen-r-703-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-6/>\n",
            "{'name': 'Мезофильная закваска для сыра БК-Углич-№6', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-hansen-r-703-50u/>\n",
            "{'name': 'Закваска мезофильная Chr.Hansen R-703 (50U)', 'price': '1 315 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-hansen-mo-10-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-40-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-hansen-mo-10-50u/>\n",
            "{'name': 'Закваска мезофильная Chr.Hansen MO-10 (50U)', 'price': '1 215 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-40-50u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM40 (50U)', 'price': '1 240 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-40-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-40-10u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM40 (10U)', 'price': '590 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-30-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-7/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-30-50u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM30 (50U)', 'price': '1 240 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-7/>\n",
            "{'name': 'Мезофильная закваска для сыра и творога БК-Углич-№7 (1ЕА)', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-30-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-30-10u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM30 (10 U)', 'price': '590 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-rsf-742/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-20-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-ld/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-rsf-742/>\n",
            "{'name': 'Мезо-термофильная закваска Hansen RSF-742 (50U)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-20-50u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM20 (50U)', 'price': '1 240 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-ld/>\n",
            "{'name': 'Вспомогательная закваска для сыра и творога БК-Углич-ЛД', 'price': '275 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/white-daily-40/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/white-daily-40/>\n",
            "{'name': 'Мезо-термофильная закваска Hansen WhiteDaily 40 (50U)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-selection-daily-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-selection-danica-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-selection-daily-10u/>\n",
            "{'name': 'Закваска Chr.Hansen Selection Daily (10U) на 100 литров молока', 'price': '410 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-selection-danica-10u/>\n",
            "{'name': 'Закваска Chr.Hansen Selection Danica (10U) на 100 литров молока', 'price': '410 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica-500-u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-dcc-26--350u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica-200-u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica-500-u/>\n",
            "{'name': 'Закваска мезофильная Hansen Flora Danica (500U) на 5 тонн', 'price': '6 690 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-dcc-26--350u/>\n",
            "{'name': 'Мезо-термофильная закваска Chr.Hansen DCC-260 (350U)', 'price': '3 950 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica-200-u/>\n",
            "{'name': 'Закваска мезофильная Hansen Flora Danica (200U) на 2 тонны', 'price': '3 290 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-lc2-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-mst/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-lc2-d-2u/>\n",
            "{'name': 'Мезофильная закваска Standa LC2 D 2U (на 100 литров молока)', 'price': '995 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-flora-danica/>\n",
            "{'name': 'Закваска мезофильная Hansen Flora Danica (50U)', 'price': '950 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-mst/>\n",
            "{'name': 'Мезофильная закваска для сыра БК-Углич-МСТ (0,1 ЕА)', 'price': '108 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-ma-20-10-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-ma-20-10-dcu/>\n",
            "{'name': 'Мезофильная закваска Danisco CHOOZIT MA 20 (10 DCU)', 'price': '435 руб.', 'in_stock': 'Нет в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/sacco-m%D0%BE-030-031-032-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:40 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/bioantibut/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/sacco-m%D0%BE-030-031-032-10u/>\n",
            "{'name': 'Мезофильная закваска Sacco MO 030/031/032 (10U)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/micromilk-mm-70-50u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/micromilk-mm-70-50u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM70 (50U)', 'price': '1 240 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/sacco-m-030-031-032-r-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/sacco-m-030-031-032-r-10u/>\n",
            "{'name': 'Мезофильная закваска Sacco M 030/031/032 R (10D)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/sacco-m-030-031-032-r-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/sacco-ms-062-064-066-cm-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/sacco-m-030-031-032-r-5u/>\n",
            "{'name': 'Мезофильная закваска Sacco M 030/031/032 R (5D)', 'price': '640 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/sacco-ms-062-064-066-cm-10u/>\n",
            "{'name': 'Мезо-термофильная закваска Sacco MS 062/064/066 CM (10D)', 'price': '1 140 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-8d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-322-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-8d-2u/>\n",
            "{'name': 'Мезо-термофильная закваска Standa CHEESE MIX 8D 2U (на 200 литров молока)', 'price': '1 490 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-lc3-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-322-d-2u/>\n",
            "{'name': 'Мезофильная закваска Standa 322 D 2U (на 200 литров молока)', 'price': '1 805 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-lc3-d-2u/>\n",
            "{'name': 'Мезофильная закваска Standa LC3 D 2U (на 200 литров молока)', 'price': '635 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-188-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-188-d-2u/>\n",
            "{'name': 'Мезо-термофильная закваска Standa CHEESE MIX 188 D 2U (на 200 литров молока)', 'price': '1 130 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-122-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-122-d-2u/>\n",
            "{'name': 'Мезофильная закваска Standa 122 D 2U (на 200 литров молока)', 'price': '1 110 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-222-d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-222-d-2u/>\n",
            "{'name': 'Мезофильная закваска Standa PAL 222 D 2U (на 200 литров молока)', 'price': '1 705 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-20u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-20u/>\n",
            "{'name': 'Мезофильно-термофильная закваска ALCE LYOBAC OTC 5/6 (20U)', 'price': '2 674 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-1d-2u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-cheese-mix-1d-2u/>\n",
            "{'name': 'Мезо-термофильная закваска Standa CHEESE MIX 1D (2U) ', 'price': '1 188 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-5u/>\n",
            "{'name': 'Мезофильно-термофильная закваска ALCE LYOBAC OTC 5/6 (5U)', 'price': '1 045 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-20u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-20u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-20u/>\n",
            "{'name': 'Мезофильно-термофильная закваска ALCE LYOBAC DHC 10/11 (20U)', 'price': '2 674 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-20u/>\n",
            "{'name': 'Мезофильная закваска LYOBAC FD 1/2 (20U)', 'price': '2 674 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/tvorog-smetana-alce-lyobac-tw-1u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/syr-tvorog-alce-lyobac-nt-1u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/tvorog-smetana-alce-lyobac-tw-1u/>\n",
            "{'name': 'Мезо-термофильная закваска ALCE LYOBAC TW (1U)', 'price': '345 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/syr-tvorog-alce-lyobac-nt-1u/>\n",
            "{'name': 'Закваска для сыра и творога ALCE LYOBAC NT (1U)', 'price': '345 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/standa-pal-tex-100l/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/standa-pal-tex-100l/>\n",
            "{'name': 'Мезо-термофильная закваска Standa PAL TEX 100l (на 100 литров молока)', 'price': '985 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-5u/>\n",
            "{'name': 'Мезофильная закваска ALCE LYOBAC FD 1/2 (5U)', 'price': '1 045 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-1u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-1u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-1u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-otc-5-6-1u/>\n",
            "{'name': 'Закваска для Чеддера ALCE LYOBAC OTC 5/6 (1U)', 'price': '345 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-1u/>\n",
            "{'name': 'Фермерская закваска ALCE LYOBAC DHC 10/11 (1U)', 'price': '345 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-fd-1-2-1u/>\n",
            "{'name': 'Мезофильная закваска ALCE LYOBAC FD 1/2 (1U)', 'price': '590 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-em-20u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-msy-4-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-1-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/alche-lyobac-dhc-10-11-5u/>\n",
            "{'name': 'Мезофильно-термофильная закваска ALCE LYOBAC DHC 10/11 (5U)', 'price': '1 045 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-em-20u/>\n",
            "{'name': 'Термофильно-мезофильная закваска Lactoferm-Biochem EM 20U (на 5 тонн)', 'price': '3 250 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-msy-4-10u/>\n",
            "{'name': 'Фермерская закваска Lactoferm-Biochem MSY (10U)', 'price': '1 225 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-1-10u/>\n",
            "{'name': 'Закваска Lactoferm-Biochem MSO (10U)', 'price': '1 145 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-20u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-20u/>\n",
            "{'name': 'Закваска Lactoferm-Biochem MSO (20U)', 'price': '1 845 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mse-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mse-10u/>\n",
            "{'name': 'Закваска Lactoferm-Biochem MSE (10U)', 'price': '1 145 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-50-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mfc-4-10u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-1-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mikromilk-mm-50-10u/>\n",
            "{'name': 'Мезофильная закваска MicroMilk MM50 (10U)', 'price': '590 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mfc-4-10u/>\n",
            "{'name': 'Закваска Lactoferm-Biochem MFC (10U)', 'price': '745 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/zakvaska-biochem-mso-1-5u/>\n",
            "{'name': 'Закваска Lactoferm-Biochem MSO (5U)', 'price': '935 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/polutverdiy-syr-lactaferm/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19-500-u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/polutverdiy-syr-lactaferm/>\n",
            "{'name': 'Закваска «Полутвердый сыр» Lactoferm ECO - на 250 литров молока', 'price': '695 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19-500-u/>\n",
            "{'name': 'Мезофильная закваска Chr.Hansen CHN-19 (500U)', 'price': '6 650 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/clerici-gal1-gal2-50-edinic/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/?page=2)\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/clerici-gal1-gal2-50-edinic/>\n",
            "{'name': 'Закваска Клеричи (Clerici) GAL1/GAL2, 50 единиц', 'price': '979 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19-200-u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19/>\n",
            "{'name': 'Мезофильная закваска Chr.Hansen CHN-19 (50U)', 'price': '1 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/hansen-chn-19-200-u/>\n",
            "{'name': 'Мезофильная закваска Chr.Hansen CHN-19 (200U)', 'price': '3 050 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-s/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-su-casu-lyo-500-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-s/>\n",
            "{'name': 'Мезофильная закваска для сыра БК-Углич-С (1ЕА)', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-su-casu-lyo-500-dcu/>\n",
            "{'name': 'Мезо-термофильная закваска SU CASU LYO 500 DCU', 'price': '6 930 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-choozit-ma-11/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-choozit-ma-11/>\n",
            "{'name': 'Мезофильная закваска Danisco CHOOZIT MA 11/16 (25 DCU)', 'price': '610 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-su-casu-lyo-50-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-su-casu-lyo-50-dcu/>\n",
            "{'name': 'Мезо-термофильная закваска SU CASU LYO 50 DCU', 'price': '1 120 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/sacco-ms-062-064-066-cm-5u/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/sacco-ms-062-064-066-cm-5u/>\n",
            "{'name': 'Мезо-термофильная закваска Sacco MS 062/064/066 CM (5D)', 'price': '790 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/termofilnye/danisco-ma-4001/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/ma-4001-5-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/termofilnye/danisco-ma-4001/>\n",
            "{'name': 'Фермерская закваска Danisco MA 4001/4002 (25 DCU)', 'price': '670 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/danisco-mm-101-250-dcu/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/ma-4001-5-dcu/>\n",
            "{'name': 'Фермерская закваска Danisco MA 4001/4002 (5 DCU)', 'price': '345 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/danisco-mm-101-250-dcu/>\n",
            "{'name': 'Мезофильная закваска Danisco CHOOZIT MM 101 (250 DCU)', 'price': '4 300 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-choozit-mm-101/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/danisco-choozit-mm-101/>\n",
            "{'name': 'Мезофильная закваска Danisco CHOOZIT MM 101 (25 DCU)', 'price': '610 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/smetana-tvorog-filadelfia/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/dlya-koziego-moloka/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/smetana-tvorog-filadelfia/>\n",
            "{'name': 'Закваска ПроСыр \"Сметана, творог и филадельфия\"', 'price': '229 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/dlya-koziego-moloka/>\n",
            "{'name': 'Закваска ПроСыр \"Для сыра из козьего молока\"', 'price': '229 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-4/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-4/>\n",
            "{'name': 'Мезофильная закваска для сыра БК-Углич-№4 (1ЕА)', 'price': '269 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/kamamber-bri/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/fermerskaya/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-5a/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/kamamber-bri/>\n",
            "{'name': 'Закваска ПроСыр \"Камамбер и бри\"', 'price': '229 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/fermerskaya/>\n",
            "{'name': 'Закваска для сыра ПроСыр \"Фермерская\"', 'price': '319 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/uglich-5a/>\n",
            "{'name': 'Мезофильная закваска для сыра БК-Углич-5А', 'price': '108 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/gauda-edam/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/gauda-edam/>\n",
            "{'name': 'Закваска ПроСыр \"Гауда и эдам\"', 'price': '229 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pro-syr.ru/zakvaski-dlya-syra/domashniy-feta-brynza/> (referer: https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/)\n",
            "2023-03-29 16:51:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://pro-syr.ru/zakvaski-dlya-syra/domashniy-feta-brynza/>\n",
            "{'name': 'Закваска ПроСыр \"Домашний сыр, фета и брынза\"', 'price': '229 руб.', 'in_stock': 'Есть в наличии'}\n",
            "2023-03-29 16:51:50 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2023-03-29 16:51:50 [scrapy.extensions.feedexport] INFO: Stored csv feed (87 items) in: vsysnii_sir.csv\n",
            "2023-03-29 16:51:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 34950,\n",
            " 'downloader/request_count': 91,\n",
            " 'downloader/request_method_count/GET': 91,\n",
            " 'downloader/response_bytes': 4457920,\n",
            " 'downloader/response_count': 91,\n",
            " 'downloader/response_status_count/200': 91,\n",
            " 'dupefilter/filtered': 53,\n",
            " 'elapsed_time_seconds': 17.137704,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2023, 3, 29, 16, 51, 50, 54102),\n",
            " 'httpcompression/response_bytes': 27445802,\n",
            " 'httpcompression/response_count': 91,\n",
            " 'item_scraped_count': 87,\n",
            " 'log_count/DEBUG': 182,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 160555008,\n",
            " 'memusage/startup': 160555008,\n",
            " 'request_depth_max': 3,\n",
            " 'response_received_count': 91,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 90,\n",
            " 'scheduler/dequeued/memory': 90,\n",
            " 'scheduler/enqueued': 90,\n",
            " 'scheduler/enqueued/memory': 90,\n",
            " 'start_time': datetime.datetime(2023, 3, 29, 16, 51, 32, 916398)}\n",
            "2023-03-29 16:51:50 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udM4Isl1RDxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "Bp_AOQKphZDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Инициализируем проект SCRAPY\n",
        "2. В папке spiders создаем своего паука\n",
        "3. Создаем класс с пауком и наследуемся от scrapy.Spider\n",
        "4. Называем паука так же, как и класс\n",
        "5. Указываем стартовую ссылку\n",
        "6. Создаем функцию парсинга карточки, где описываем получение данных из карточки в словарь (название, цена и запас). Возвращаем обратно словарь через yield.\n",
        "7. Создаем функцию parse — основую логику перехода по ссылкам\n",
        "8. Получаем ссылки на каждую карточек текущей страницы\n",
        "9. Циклом проходимся по каждой и собираем данные через ранне коллбек функцию\n",
        "10. Дальше в функции parse расписываем переход на следующую страницу. Для этого находим в пагинации ссылку на следующую страницу  и переходим на нее до тех пор, пока она не закончится.\n",
        "11. В командной строке переходим в папку с проектом scrapy (%cd <название проекта>/) \n",
        "12. В командной строке пишем команду !scrapy runspider <название паука или путь до него из папки с проектом> -o <Название файла с форматом csv, куда будет записан результат парсинга>\n",
        "\n",
        "\n",
        "Не забывайте пользоваться scrapy shell!"
      ],
      "metadata": {
        "id": "s2id-iqTmngO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Дополнительно (по желанию)**"
      ],
      "metadata": {
        "id": "uKGJfcM39R62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание. Собираем данные с помощью Requests"
      ],
      "metadata": {
        "id": "cJL8g8Cy96Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью методов API ВКонтакте получите список высших учебных заведений и названия их факультетов в городе Томск.\n",
        "Результат должен быть записан в файл JSON в следующем формате:"
      ],
      "metadata": {
        "id": "MgvkdXgsex5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiF3TeikBTrD"
      },
      "outputs": [],
      "source": [
        "\"result\": {\n",
        "  \"cities\": [\n",
        "    {   \n",
        "        \"id\": <ID города>,\n",
        "        \"name\": <Название города>,\n",
        "        \"universites\": [\n",
        "            {\n",
        "              \"id\": <ID ВУЗа>, \n",
        "              \"name\": <Название ВУЗа>\n",
        "              \"faculties\": [<Название факультета>, …]\n",
        "            },\n",
        "            ...\n",
        "        ]\n",
        "    },\n",
        "    ...\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbPFOD0999QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "eQ8qxWmA-GlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Получаем токен доступа к API Вконтакте\n",
        "2.   Настраиваем подключение к API Вконтакте  и устанавливаем базовые параметры (токен и версия) GET запроса\n",
        "\n",
        "---\n",
        "\n",
        "3. Следуя методу из документации для получения городов и используя библиотеку requests, составляем запрос на получение информации о городе «Томск» и получаем его id и название из ответа на запрос\n",
        "\n",
        "---\n",
        "4. Следуя методу из документации для получения университетов и используя библиотеку requests, составляем запрос на получение информации о университетах города «Томск» (по найденному id) и получаем список университетов\n",
        "5. Из полученного списка университетов получаем id и название каждого\n",
        "6. Список id и названия университетов записываем в словарь с информацией о найденном городе под ключем 'universites'\n",
        "---\n",
        "\n",
        "7. Находим метод получения факультетов университета в документации API Вконтакте\n",
        "8. Через цикл по каждому id университета, составляем запрос на получение информации о факультете университета (по найденному id) и получаем список названий факультетов\n",
        "9. В этом же цикле записываем под ключем 'faculties' полученный список\n",
        "---\n",
        "10. Создаем финальный словарь с ключем 'result', значение которого будет еще один словарь 'cities' со значением созданного нами словаря с информацией о городе-университетах-факультетах\n",
        "11. Записываем наш словарь в  файл с форматом JSON\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1DiivPHK833t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример решения задачи-аналога: https://colab.research.google.com/drive/1kvqcs1R8oRueCa_EajNXdV4w1qr6DCgA?usp=sharing"
      ],
      "metadata": {
        "id": "dI54GXxV-6rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание. Библиотека BeautifulSoup"
      ],
      "metadata": {
        "id": "xGVZmQlN9k8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написать код, который соберет список знаменательных дат в формате «чисто месяц год» с первой страницы сайта GCTC.ru (https://www.gctc.ru/main.php?id=98.1)"
      ],
      "metadata": {
        "id": "EvfKn3WArL8X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sdn8-Ot-9eSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "Z5fdkDqd9qq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Устанавливаем bs4\n",
        "2. Здесь lxml неправильно декодирует html в дерево супа (это можно узнать путем проб и ошибок)\n",
        "3. Устанавливаем любой другой парсер и проверяем, что он нормально декодирует (html5lib подходит)\n",
        "\n",
        "4. С помощью requests инициализируем сессию, используя указанную ссылку, и устанавливем заголовки\n",
        "5. Получаем из проинициализированной сессии text и варим суп\n",
        "6. Получаем главный блок с помощью селектора из которого нужно достать данные\n",
        "7. Получаем все теги h2, которые содержат год \n",
        "8. Создаем результативный массив и в цикле по каждому тегу h2 будем записывать в него полученный результат\n",
        "9. В цикле обрезаем .г у года, Получаем ОДИН h1, который был до div.news h2 с помощью метода find_previous (это и есть день и месяц события)\n",
        "10. Получаем дату+месяц, где первые два символа это день, а остальные символы это название месяца\n",
        "11. Записываем все в результативный массив\n",
        "\n",
        "\n",
        "Не забываем все обернуть в try except и проверять с помощью raise_for_status"
      ],
      "metadata": {
        "id": "ar3LJKizE3E7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание. Библиотека Selenium"
      ],
      "metadata": {
        "id": "4refkAJceIVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написать код, который выполнит ввод слова «Lenovo» в поисковую строку сайта  nbcomputers.ru (https://www.nbcomputers.ru/) и начнет поиск\n",
        "<br>\n",
        "<br>\n",
        "![Поиск.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAApQAAAAyCAYAAADiFUvmAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAATUSURBVHhe7d3PalNZHMDxeYx5CH2eER/CheAM6GIWA8K8jOAMwiy0MdQQSo2xtknHli7aGvtvNEiQtJTym3uSmzZm0iblitPYzwcO7UnvbaGrL+fck/wQAABQgKAEAKAQQQkAQCGCEgCAQgQlAACFTAzKR1ut+OnFYtx4Mhc/PvrLMAzDMAzDuCYj9d+trAMfb+/kZTjehUH5c70R916tRGn3IPa7h/mrAABcB6n/5rIOvFtbjgevm/mr/3VuUP6SxeTvzfV8BgDAdfawsRb3z4nKsUH56N1O3Kuv5DMAAIi4+2olHmedOGpsUKZnJkt7/+QzAACIeLp7ELcrL/PZmbFBmR7A3D88ymcAABCx1z2Mm1knjhoblOlUDwAAjBrXiYISAICpCUoAAAoRlAAAFCIoAQAoRFACAHzHPn78GEtLS1Eul+PZs2e9r81mM7rdbn5FcYISAOA7dHx83AvHFJHPnz+PWq0Wa2trva/ptTS2trbyq4v5xkHZjkalFKXaZj4fthm1UikqjXY+n0Yr6uX5WNo5zv5rO7E0X4radv4jAIBrrNFo9KIxfU1xOSytTg7C8mtE5YwHZfYPaS1FJbuvlI35+mZ8vcVbAIDZlLa5BzF5kYWFhd4WeNHt75kPSgAAvpSemUzb3KMrk6MG4Vl0lfJKB+VxeyPq1XJv9bG3ArnYiJ3TgO5fP/yrjrZrUR681m6crlyOjv7fmHA/AMCMGjwzOY3LXHueqxuURxuxmObLrWh3j+LoUyuW072LG9H/RPGRIDxJz1P2g3H012/WstcrjeyvD5v+fgCAWZJWHdMBnGmkmJzNoMyi7bxxGpQnR/G58zmOTvrTpN2oDIXhcBCexN7yfJSq1aievnZmclBefD8AwCy57Apl2iIv4v8JysX16HQ6I2O9vyI5tOXd3VmN2tCWd2+MCcqTD2l7uxKr7ZFVx9ykoJx0PwDALBmc8J502Ob9+/ff+TOUnbdRLZWj2mhFJ3+edPwKZTtWs99ZaXyIky9WHc9cHJST7wcAmCUpJFMoXrRKmQ7sVCqVqQ7vTHJ1g3KzFqVSLXv1zIcxQVmtVqM0vxx7va3xywflNPcDAMyatOqYojK9NVA6zT1sf3+/F5Pp50W3u5OrG5QHyzGf5ulQTqcTBxu13rxUrkerd0H/+lKpHPXW4EHLywflNPcDAMyiFJVpBTKFY3q/ybRiOfgIxsGzk+n79Ik6RVzdoIyT+LRZj0p+8rpcqcfm6mL2/UKs9455968v17bzU9/J5YNymvsBAGZV2v5OYTk4zZ0iMs0H29yD5y2LROU3DkoAAK6aolEpKAEAOI3Kad+/cpigBACgJ0VlOsRzWYISAIBCBCUAAIUISgAAChGUAAAUIigBAChEUAIAUIigBACgkKmD8saTudg/PPuQQgAA2Osexs2sE0eNDcpbLxZjbvcgnwEAQMTTrA9vV17mszNjg/Lxu524W1vJZwAAEHHn5Zv4s7Wbz86MDcrkwVIzHjbX8xkAANfZbytv49c3f+ezL50blMn9183eSmVa3kx75gAAXB+p/1IH3qktnxuTyYVBmfzxbqe3V54ewEynegzDMAzDMIzrMVL/pQ4ct809bGJQAgDARQQlAACFCEoAAAoRlAAAFCIoAQAoIOJfo8wRgBFQ9M8AAAAASUVORK5CYII=)\n",
        "\n",
        "*(подсказка: изучите внимательно документацию и методы wait.until, click или send_keys)*"
      ],
      "metadata": {
        "id": "6JTr57BPdOpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL9552d2_PFO",
        "outputId": "dbfbef6d-4af0-4cbd-8bcd-dd19f8c33b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing: /tmp/apt-key-gpghome.Je0hczM9J4/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
            "gpg: key DCC9EFBF77E11517: public key \"Debian Stable Release Key (10/buster) <debian-release@lists.debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Executing: /tmp/apt-key-gpghome.MB07iGRF8a/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
            "gpg: key DC30D7C23CBBABEE: public key \"Debian Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Executing: /tmp/apt-key-gpghome.JO6h2oQHJk/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
            "gpg: key 4DFAB270CAA96DFA: public key \"Debian Security Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Get:1 http://deb.debian.org/debian buster InRelease [122 kB]\n",
            "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:3 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]\n",
            "Get:4 http://deb.debian.org/debian-security buster/updates InRelease [34.8 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:9 http://deb.debian.org/debian buster/main amd64 Packages [10.7 MB]\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:12 http://deb.debian.org/debian buster-updates/main amd64 Packages [9,745 B]\n",
            "Get:13 http://deb.debian.org/debian-security buster/updates/main amd64 Packages [601 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:17 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,589 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,027 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,060 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,322 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,068 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,198 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,412 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,143 kB]\n",
            "Fetched 27.7 MB in 4s (7,895 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-common chromium-sandbox libevent-2.1-6 libicu63 libimobiledevice6\n",
            "  libjpeg62-turbo libplist3 libre2-5 libu2f-udev libusbmuxd6 libvpx5\n",
            "  libxxf86dga1 upower usbmuxd x11-utils\n",
            "Suggested packages:\n",
            "  chromium-l10n chromium-shell libusbmuxd-tools mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  chromium chromium-common chromium-driver chromium-sandbox libevent-2.1-6\n",
            "  libicu63 libimobiledevice6 libjpeg62-turbo libplist3 libre2-5 libu2f-udev\n",
            "  libusbmuxd6 libvpx5 libxxf86dga1 upower usbmuxd x11-utils\n",
            "0 upgraded, 17 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 74.6 MB of archives.\n",
            "After this operation, 256 MB of additional disk space will be used.\n",
            "Get:1 http://deb.debian.org/debian buster/main amd64 libevent-2.1-6 amd64 2.1.8-stable-4 [177 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libre2-5 amd64 20200101+dfsg-1build1 [162 kB]\n",
            "Get:3 http://deb.debian.org/debian buster/main amd64 libicu63 amd64 63.1-6+deb10u3 [8,293 kB]\n",
            "Get:4 http://deb.debian.org/debian buster/main amd64 libjpeg62-turbo amd64 1:1.5.2-2+deb10u1 [133 kB]\n",
            "Get:5 http://deb.debian.org/debian buster/main amd64 libvpx5 amd64 1.7.0-3+deb10u1 [800 kB]\n",
            "Get:6 http://deb.debian.org/debian buster/main amd64 chromium-common amd64 90.0.4430.212-1~deb10u1 [1,423 kB]\n",
            "Get:7 http://deb.debian.org/debian buster/main amd64 chromium amd64 90.0.4430.212-1~deb10u1 [58.3 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libplist3 amd64 2.1.0-4build2 [31.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libusbmuxd6 amd64 2.0.1-2 [19.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libimobiledevice6 amd64 1.2.1~git20191129.9f79242-1build1 [65.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6,108 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 upower amd64 0.99.11-1build2 [104 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 usbmuxd amd64 1.1.1~git20191130.9af2b12-1 [38.4 kB]\n",
            "Get:16 http://deb.debian.org/debian buster/main amd64 chromium-driver amd64 90.0.4430.212-1~deb10u1 [4,703 kB]\n",
            "Get:17 http://deb.debian.org/debian buster/main amd64 chromium-sandbox amd64 90.0.4430.212-1~deb10u1 [146 kB]\n",
            "Fetched 74.6 MB in 1s (106 MB/s)\n",
            "Selecting previously unselected package libevent-2.1-6:amd64.\n",
            "(Reading database ... 128285 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libevent-2.1-6_2.1.8-stable-4_amd64.deb ...\n",
            "Unpacking libevent-2.1-6:amd64 (2.1.8-stable-4) ...\n",
            "Selecting previously unselected package libicu63:amd64.\n",
            "Preparing to unpack .../01-libicu63_63.1-6+deb10u3_amd64.deb ...\n",
            "Unpacking libicu63:amd64 (63.1-6+deb10u3) ...\n",
            "Selecting previously unselected package libjpeg62-turbo:amd64.\n",
            "Preparing to unpack .../02-libjpeg62-turbo_1%3a1.5.2-2+deb10u1_amd64.deb ...\n",
            "Unpacking libjpeg62-turbo:amd64 (1:1.5.2-2+deb10u1) ...\n",
            "Selecting previously unselected package libre2-5:amd64.\n",
            "Preparing to unpack .../03-libre2-5_20200101+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libre2-5:amd64 (20200101+dfsg-1build1) ...\n",
            "Selecting previously unselected package libvpx5:amd64.\n",
            "Preparing to unpack .../04-libvpx5_1.7.0-3+deb10u1_amd64.deb ...\n",
            "Unpacking libvpx5:amd64 (1.7.0-3+deb10u1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5) ...\n",
            "Selecting previously unselected package chromium-common.\n",
            "Preparing to unpack .../07-chromium-common_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-common (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium.\n",
            "Preparing to unpack .../08-chromium_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium-driver.\n",
            "Preparing to unpack .../09-chromium-driver_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-driver (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium-sandbox.\n",
            "Preparing to unpack .../10-chromium-sandbox_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-sandbox (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package libplist3:amd64.\n",
            "Preparing to unpack .../11-libplist3_2.1.0-4build2_amd64.deb ...\n",
            "Unpacking libplist3:amd64 (2.1.0-4build2) ...\n",
            "Selecting previously unselected package libusbmuxd6:amd64.\n",
            "Preparing to unpack .../12-libusbmuxd6_2.0.1-2_amd64.deb ...\n",
            "Unpacking libusbmuxd6:amd64 (2.0.1-2) ...\n",
            "Selecting previously unselected package libimobiledevice6:amd64.\n",
            "Preparing to unpack .../13-libimobiledevice6_1.2.1~git20191129.9f79242-1build1_amd64.deb ...\n",
            "Unpacking libimobiledevice6:amd64 (1.2.1~git20191129.9f79242-1build1) ...\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "Preparing to unpack .../14-libu2f-udev_1.1.10-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.10-1) ...\n",
            "Selecting previously unselected package upower.\n",
            "Preparing to unpack .../15-upower_0.99.11-1build2_amd64.deb ...\n",
            "Unpacking upower (0.99.11-1build2) ...\n",
            "Selecting previously unselected package usbmuxd.\n",
            "Preparing to unpack .../16-usbmuxd_1.1.1~git20191130.9af2b12-1_amd64.deb ...\n",
            "Unpacking usbmuxd (1.1.1~git20191130.9af2b12-1) ...\n",
            "Setting up libplist3:amd64 (2.1.0-4build2) ...\n",
            "Setting up libu2f-udev (1.1.10-1) ...\n",
            "Failed to send reload request: No such file or directory\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Setting up chromium-sandbox (90.0.4430.212-1~deb10u1) ...\n",
            "Setting up libicu63:amd64 (63.1-6+deb10u3) ...\n",
            "Setting up libjpeg62-turbo:amd64 (1:1.5.2-2+deb10u1) ...\n",
            "Setting up libevent-2.1-6:amd64 (2.1.8-stable-4) ...\n",
            "Setting up libusbmuxd6:amd64 (2.0.1-2) ...\n",
            "Setting up x11-utils (7.7+5) ...\n",
            "Setting up libre2-5:amd64 (20200101+dfsg-1build1) ...\n",
            "Setting up chromium-common (90.0.4430.212-1~deb10u1) ...\n",
            "Setting up libimobiledevice6:amd64 (1.2.1~git20191129.9f79242-1build1) ...\n",
            "Setting up libvpx5:amd64 (1.7.0-3+deb10u1) ...\n",
            "Setting up upower (0.99.11-1build2) ...\n",
            "Setting up usbmuxd (1.1.1~git20191130.9af2b12-1) ...\n",
            "Warning: The home dir /var/lib/usbmux you specified can't be accessed: No such file or directory\n",
            "Adding system user `usbmux' (UID 107) ...\n",
            "Adding new user `usbmux' (UID 107) with group `plugdev' ...\n",
            "Not creating home directory `/var/lib/usbmux'.\n",
            "Setting up chromium (90.0.4430.212-1~deb10u1) ...\n",
            "update-alternatives: using /usr/bin/chromium to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-driver (90.0.4430.212-1~deb10u1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for dbus (1.12.16-2ubuntu2.3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.8.3-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.9/dist-packages (from selenium) (2022.12.7)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.9/dist-packages (from selenium) (1.26.15)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (22.2.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.8.3 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install chromium and chromium-driver\n",
        "!apt-get update\n",
        "!apt-get install chromium chromium-driver\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YcjfwyLRsG8",
        "outputId": "6e9bf39d-d53c-4100-f429-972d604f7406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connected to cloud.r-project.org (108.15\r                                                                               \rHit:2 http://deb.debian.org/debian buster InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r                                                                               \rHit:3 http://deb.debian.org/debian buster-updates InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r                                                                               \rHit:5 http://deb.debian.org/debian-security buster/updates InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium is already the newest version (90.0.4430.212-1~deb10u1).\n",
            "chromium-driver is already the newest version (90.0.4430.212-1~deb10u1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install selenium\n",
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilkNnGFzSt6t",
        "outputId": "5ee46c2e-42c7-4a02-e8ec-11fdc1402395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.9/dist-packages (4.8.3)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.9/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.10.2)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.9/dist-packages (from selenium) (1.26.15)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (22.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.9/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument(\"window-size=1920,1080\")\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('/usr/bin/chromedriver',options=chrome_options)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    driver.get(\"https://www.nbcomputers.ru/\")\n",
        "    driver.implicitly_wait(10)\n",
        "    bt_search = driver.find_element(By.CSS_SELECTOR, 'input.ant-input')\n",
        "    ActionChains(driver).move_to_element(bt_search).click(bt_search).send_keys('Lenovo\\n').perform() \n",
        "    # bt_search.send_keys('Lenovo\\n')\n",
        "except Exception as ex:\n",
        "    print(f'Error: {ex}')\n",
        "\n",
        "html = driver.page_source\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "ePDfEe4YeMea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56153079-10cb-4852-ed77-1984b746f9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-de8825436f62>:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome('/usr/bin/chromedriver',options=chrome_options)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возможный алгоритм решения задачи:"
      ],
      "metadata": {
        "id": "fjaTZHAIeLRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможный алгоритм решения задачи в коллабе (простой):\n",
        "1. Установливаем параметры для headless браузера\n",
        "2. Инициализацируем сессию браузера\n",
        "3. Переходим по данной ссылке\n",
        "4. Находим элемент по селектору\n",
        "5. С помощью метода send_keys и \\n в конце строки (\\n имитирует нажатие кнопки Enter) выполняем поиск\n",
        "\n",
        "Более сложный  и верный с использованием ожиданий\n"
      ],
      "metadata": {
        "id": "x0ngTW2zjv7A"
      }
    }
  ]
}